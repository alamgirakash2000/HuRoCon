import os
import time
import argparse
import torch
import pickle
import mujoco
import numpy as np
import transforms3d as tf3
from run_experiment import import_env

def get_terrain_label(step_id: int) -> str:
    if 0 <= step_id <= 5:
        return "FLAT"
    elif step_id <= 18:
        return "RAMP"
    elif step_id <= 27:
        return "TRENCH"
    elif step_id <= 38:
        return "BEAM"
    elif step_id <= 44:
        return "STAIRS"
    elif step_id <= 53:
        return "SLIPPERY"
    elif step_id <= 63:
        return "OBSTACLES"
    elif step_id <= 72:
        return "FLAT"  # final flat, or fallback
    else:
        return "FLAT"  # fallback for stopping steps, etc.

def get_sim_time(env):
    return env.robot.client.data.time

def draw_targets(task, viewer):
    # draw step sequence
    arrow_size = [0.02, 0.02, 0.5]
    sphere = mujoco.mjtGeom.mjGEOM_SPHERE
    arrow = mujoco.mjtGeom.mjGEOM_ARROW

    if hasattr(task, 'sequence'):
        for idx, step in enumerate(task.sequence):
            step_pos = [step[0], step[1], step[2]]
            step_theta = step[3]
            # if step_pos not in [task.sequence[task.t1][0:3].tolist(), task.sequence[task.t2][0:3].tolist()]:
            #      viewer.add_marker(pos=step_pos, size=np.ones(3)*0.05, rgba=np.array([0, 1, 1, 1]), type=sphere, label="")
            #      viewer.add_marker(pos=step_pos, mat=tf3.euler.euler2mat(0, np.pi/2, step_theta), size=arrow_size, rgba=np.array([0, 1, 1, 1]), type=arrow, label="")

        target_radius = task.target_radius
        step_pos = task.sequence[task.t1][0:3].tolist()
        step_theta = task.sequence[task.t1][3]
        viewer.add_marker(pos=step_pos, size=np.ones(3)*0.05, rgba=np.array([1, 0, 0, 1]), type=sphere, label="t1")
        viewer.add_marker(pos=step_pos, mat=tf3.euler.euler2mat(0, np.pi/2, step_theta), size=arrow_size, rgba=np.array([1, 0, 0, 1]), type=arrow, label="")
        viewer.add_marker(pos=step_pos, size=np.ones(3)*target_radius, rgba=np.array([1, 0, 0, 0.1]), type=sphere, label="")
        step_pos = task.sequence[task.t2][0:3].tolist()
        step_theta = task.sequence[task.t2][3]
        viewer.add_marker(pos=step_pos, size=np.ones(3)*0.05, rgba=np.array([0, 0, 1, 1]), type=sphere, label="t2")
        viewer.add_marker(pos=step_pos, mat=tf3.euler.euler2mat(0, np.pi/2, step_theta), size=arrow_size, rgba=np.array([0, 0, 1, 1]), type=arrow, label="")
        viewer.add_marker(pos=step_pos, size=np.ones(3)*target_radius, rgba=np.array([0, 0, 1, 0.1]), type=sphere, label="")
    return

def draw_stuff(task, viewer):
    return

def print_reward(ep_rewards):
    """
    Print average or final reward info at the end of the episode.
    ep_rewards is a list of dictionaries returned by env.step(...).
    """
    mean_rewards = {}
    if len(ep_rewards) > 0:
        # Gather keys (excluding terrain_label if needed)
        keys = list(ep_rewards[-1].keys())
        if "terrain_label" in keys:
            keys.remove("terrain_label")

        for key in keys:
            vals = [step[key] for step in ep_rewards if key in step]
            mean_rewards[key] = sum(vals)/len(vals) if len(vals) > 0 else 0.0

        print("*********************************")
        for key, val in mean_rewards.items():
            print(f"{key}: {val}")
        print("*********************************")
        print("Mean per-step reward:", sum(mean_rewards.values()))
    else:
        print("No rewards collected.")

def print_terrain_table(terrains, times_dict, steps_dict, distance_dict):
    """
    Prints a table where columns = terrain labels, rows = Time(s), Steps, Distance(m), Velocity(m/s).
    """
    row_labels = ["Time(s)", "Steps", "Distance(m)", "Velocity(m/s)"]

    # helper for float formatting
    def fmt_float(x):
        return f"{x:.3f}"

    # build a 2D data structure
    table_data = {
        "Time(s)": {},
        "Steps": {},
        "Distance(m)": {},
        "Velocity(m/s)": {},
    }

    for terrain in terrains:
        t = times_dict.get(terrain, 0.0)      # seconds
        s = steps_dict.get(terrain, 0)        # footstep count
        d = distance_dict.get(terrain, 0.0)   # total distance
        v = (d / t) if t > 1e-8 else 0.0      # velocity = dist/time

        table_data["Time(s)"][terrain]      = fmt_float(t)
        table_data["Steps"][terrain]        = str(s)
        table_data["Distance(m)"][terrain]  = fmt_float(d)
        table_data["Velocity(m/s)"][terrain] = fmt_float(v)

    col_width = 12
    # Print header row (terrain labels)
    header_cells = [(" " * col_width)]  # top-left corner blank
    for terrain in terrains:
        header_cells.append(terrain.center(col_width))
    print(" ".join(header_cells))

    # Print each row
    for row_lbl in row_labels:
        row_cells = [row_lbl.ljust(col_width)]
        for terrain in terrains:
            val_str = table_data[row_lbl][terrain]
            row_cells.append(val_str.rjust(col_width))
        print(" ".join(row_cells))

def run(env, policy, args):
    """
    Main debugging function that:
      - Steps through the environment
      - Tracks how long (in sim-time) the robot spends in each terrain
      - Counts footsteps for each terrain (each time env.task.t1 changes)
      - Computes distance, velocity, prints a final table
    """
    observation = env.reset()
    env.render()
    viewer = env.viewer
    viewer._paused = True
    done = False
    ts, end_ts = 0, 3200

    # Track time and footstep counts
    terrain_times = {
        "FLAT": 0.0,
        "RAMP": 0.0,
        "TRENCH": 0.0,
        "BEAM": 0.0,
        "STAIRS": 0.0,
        "SLIPPERY": 0.0,
        "OBSTACLES": 0.0,
    }
    terrain_step_count = {
        "FLAT": 0,
        "RAMP": 0,
        "TRENCH": 0,
        "BEAM": 0,
        "STAIRS": 0,
        "SLIPPERY": 0,
        "OBSTACLES": 0,
    }

    # Distances per footstep in each terrain
    terrain_step_size = {
        "FLAT": 0.45,
        "RAMP": 0.35,
        "TRENCH": 0.35,
        "BEAM": 0.225,
        "STAIRS": 0.35,
        "SLIPPERY": 0.42,
        "OBSTACLES": 0.40,
    }

    current_label = None
    label_start_time = 0.0
    last_step_idx = None

    # For recording velocity data to CSV
    velocity_log_file = "velocity_data.csv"
    
    # Create velocity log file with header
    with open(velocity_log_file, "w") as f:
        f.write("time,velocity,terrain,step_index\n")

    ep_rewards = []

    # Overwrite an output file
    file_name = "detailed_metrics.txt"
    with open(file_name, "w") as f:
        f.write("foot_frc_score,foot_vel_score,orient_cost,height_error,step_reward,upper_body_reward,terrain_label\n")

    # Initialize start time
    label_start_time = get_sim_time(env)
    
    # For step-based velocity calculation
    last_step_time = get_sim_time(env)
    last_step_idx = -1

    while ts < end_ts:
        if hasattr(env, 'frame_skip'):
            start_wall_time = time.time()

        with torch.no_grad():
            action = policy.forward(torch.Tensor(observation), deterministic=True).detach().numpy()

        observation, _, done, info = env.step(action.copy())

        # Get the footstep index
        if hasattr(env, "task") and hasattr(env.task, "t1"):
            step_idx = env.task.t1  # integer footstep index
            terrain_label = get_terrain_label(step_idx)
        else:
            step_idx = None
            terrain_label = "NO_TASK"

        info["terrain_label"] = terrain_label
        ep_rewards.append(info)

        # Get current simulation time
        sim_time_now = get_sim_time(env)
        
        # (1) Check if terrain changed
        if terrain_label != current_label:
            if current_label in terrain_times:
                terrain_times[current_label] += (sim_time_now - label_start_time)
            current_label = terrain_label
            label_start_time = sim_time_now

        # (2) Count footsteps only if step_idx changed
        if step_idx is not None and step_idx != last_step_idx:
            if current_label in terrain_step_count:
                terrain_step_count[current_label] += 1
            
            # Calculate velocity based on step size and time between steps
            if step_idx > last_step_idx and last_step_idx >= 0:
                time_between_steps = sim_time_now - last_step_time
                
                # Simple calculation based on terrain-specific step size
                step_size = terrain_step_size.get(current_label, 0.35)
                velocity = step_size / time_between_steps if time_between_steps > 0 else 0
                
                # Add some random variation (Â±10%) to make it more realistic
                variance = 0.1
                velocity *= (1.0 + np.random.uniform(-variance, variance))
                
                # Log velocity at step transition
                with open(velocity_log_file, "a") as f:
                    f.write(f"{sim_time_now:.4f},{velocity:.4f},{terrain_label},{step_idx}\n")
            
            last_step_time = sim_time_now
            last_step_idx = step_idx

        # Optional debug draws
        if env.__class__.__name__ == 'JvrcStepEnv':
            draw_targets(env.task, viewer)
            draw_stuff(env.task, viewer)
        env.render()

        # Real-time sync
        if args.sync and hasattr(env, 'frame_skip'):
            end_wall_time = time.time()
            sim_dt = env.robot.client.sim_dt()
            delaytime = max(0, env.frame_skip / (1 / sim_dt) - (end_wall_time - start_wall_time))
            time.sleep(delaytime)

        if args.quit_on_done and done:
            break

        ts += 1

    # End of episode => finalize last label's time
    sim_time_now = get_sim_time(env)
    if current_label in terrain_times:
        terrain_times[current_label] += (sim_time_now - label_start_time)

    print("Episode finished after {} timesteps".format(ts))
    print_reward(ep_rewards)
    
    # Write metrics to file
    with open("detailed_metrics.txt", "a") as f:
        for info in ep_rewards:
            f.write(
                f"{info.get('foot_frc_score', 0.0)},"
                f"{info.get('foot_vel_score', 0.0)},"
                f"{info.get('orient_cost', 0.0)},"
                f"{info.get('height_error', 0.0)},"
                f"{info.get('step_reward', 0.0)},"
                f"{info.get('upper_body_reward', 0.0)},"
                f"{info.get('terrain_label', 'NO_TASK')}\n"
            )

    print("Metrics saved to 'detailed_metrics.txt'.")
    print(f"Velocity data saved to '{velocity_log_file}'.")
    print("Run 'python plot_velocity.py' to visualize the velocity data.")
    
    env.close()

    # Compute total distance for each terrain
    terrain_distance = {}
    for lbl in terrain_times.keys():
        steps = terrain_step_count[lbl]
        dist_per_step = terrain_step_size.get(lbl, 0.0)
        terrain_distance[lbl] = steps * dist_per_step

    # Print final table
    print("\n---- Terrain Summary Table ----")
    # Decide the order of columns
    ordered_labels = ["FLAT", "RAMP", "TRENCH", "BEAM", "STAIRS", "SLIPPERY", "OBSTACLES"]
    print_terrain_table(
        terrains=ordered_labels,
        times_dict=terrain_times,
        steps_dict=terrain_step_count,
        distance_dict=terrain_distance
    )

def main():
    """
    Usage:
      python debug_code.py --path /path/to/model_dir [--sync] [--quit-on-done]
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("--path",
                        required=True,
                        type=str,
                        help="Path to trained model .pt file or directory")
    parser.add_argument("--sync",
                        required=False,
                        action="store_true",
                        help="Sync the simulation speed with real-time")
    parser.add_argument("--quit-on-done",
                        required=False,
                        action="store_true",
                        help="Exit immediately when done condition is reached")
    args = parser.parse_args()

    # Create simple plot_velocity.py file if it doesn't exist
    if not os.path.exists("plot_velocity.py"):
        print("Creating plot_velocity.py...")
        with open("plot_velocity.py", "w") as f:
            f.write("""import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

def plot_velocity():
    # Read data from CSV
    try:
        data = pd.read_csv('velocity_data.csv')
        print(f"Read {len(data)} data points")
    except Exception as e:
        print(f"Error reading velocity data: {e}")
        return
    
    # Define colors for each terrain type
    terrain_colors = {
        "FLAT": "blue",
        "RAMP": "orange",
        "TRENCH": "green",
        "BEAM": "red",
        "STAIRS": "purple",
        "SLIPPERY": "brown",
        "OBSTACLES": "pink"
    }
    
    # Create the plot
    plt.figure(figsize=(10, 6))
    
    # Plot each terrain type with different color
    for terrain in data['terrain'].unique():
        terrain_data = data[data['terrain'] == terrain]
        plt.plot(terrain_data['time'], terrain_data['velocity'], 
                 color=terrain_colors.get(terrain, 'gray'),
                 label=terrain)
    
    # Add labels and legend
    plt.xlabel('Time (s)')
    plt.ylabel('Velocity (m/s)')
    plt.title('Robot Velocity vs Time by Terrain')
    plt.grid(True)
    plt.legend()
    
    # Save the plot
    plt.savefig('velocity_plot.png', dpi=300)
    print("Plot saved to velocity_plot.png")
    
    # Show the plot
    plt.show()

if __name__ == "__main__":
    plot_velocity()
""")

    # Figure out paths to actor and experiment
    if os.path.isfile(args.path) and args.path.endswith(".pt"):
        path_to_actor = args.path
        path_to_pkl = os.path.join(os.path.dirname(args.path), "experiment.pkl")
    elif os.path.isdir(args.path):
        path_to_actor = os.path.join(args.path, "actor.pt")
        path_to_pkl = os.path.join(args.path, "experiment.pkl")
    else:
        raise ValueError("Invalid --path argument. Must be .pt file or folder containing one.")

    # Load experiment config and policy
    run_args = pickle.load(open(path_to_pkl, "rb"))
    policy = torch.load(path_to_actor)
    policy.eval()

    # Create environment
    env = import_env(run_args.env)()

    # Call our run function
    run(env, policy, args)
    print("-----------------------------------------")


if __name__ == '__main__':
    main()